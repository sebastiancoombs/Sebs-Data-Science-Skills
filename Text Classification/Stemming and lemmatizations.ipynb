{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47538b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=['i like this book','shoes are alright', 'i like the books','i lost a shoe']\n",
    "y_train=['books','books','clothings','clothings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfab3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00856fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect=CountVectorizer()\n",
    "\n",
    "vect.fit(X_train)\n",
    "x_train_dtm =vect.transform(X_train)\n",
    "\n",
    "nb_clf=MultinomialNB()\n",
    "\n",
    "nb_clf.fit(x_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615dc0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['books', 'books', 'clothings', 'clothings'], dtype='<U9')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test= ['i like this book','shoes are alright', 'i like the books','i lost a shoe']\n",
    "X_test_dtm= vect.transform(X_test)\n",
    "nb_clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d60cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # natual languague tool kit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a63e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sebastian.coombs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sebastian.coombs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sebastian.coombs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sebastian.coombs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e113256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9462ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef481053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('reading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dae74d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'book'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "596413b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'book'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('booked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9970521",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase='I love the books'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2309be04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'the', 'books']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=word_tokenize(phrase)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee8da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words=[stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c5c96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'the', 'book']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "055a0f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love the book'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d377eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ate\n",
      "eat\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem('ate'))\n",
    "print(stemmer.stem('eat'))\n",
    "print(stemmer.stem('eats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19aed821",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stemmer is easy to use but can miss verbs in different forms\n",
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "215e6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet #?\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67268111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('love', 'VBP'), ('the', 'DT'), ('books', 'NNS')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it expects the words and parts of speech\n",
    "# parts of speech\n",
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81b22722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pos(pos):\n",
    "    if pos.startswith('J'): #adjective\n",
    "        return 'a'\n",
    "    elif pos.startswith('V'): #verb\n",
    "        return 'v'\n",
    "    elif pos.startswith('N'): #noun\n",
    "        return 'n'\n",
    "    elif pos.startswith('R'): #adverb\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82322cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eat\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "print (lemmatizer.lemmatize('ate',pos='v'))\n",
    "print (lemmatizer.lemmatize('eat',pos='v'))\n",
    "print (lemmatizer.lemmatize('eats',pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "648d5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words= [lemmatizer.lemmatize(word,pos=process_pos(pos)) for word ,pos in nltk.pos_tag(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e05ed08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love the book'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eae7c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "636cbf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['here',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sentence',\n",
       " 'demonstrating',\n",
       " 'the',\n",
       " 'removal',\n",
       " 'of',\n",
       " 'stop',\n",
       " 'words']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase='here is a sentence demonstrating the removal of stop words'\n",
    "words = word_tokenize(phrase)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e55518ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3391f106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence', 'demonstrating', 'removal', 'stop', 'words']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5487d36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Punctuation Removal\n",
    "phrase= 'Hello! How are you?'\n",
    "words=word_tokenize(phrase)\n",
    "\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b59b2d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation=[punc for punc in string.punctuation]\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19a9d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in words if word not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97e66739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  My wife took me here on my birthday for breakf...      5\n",
       "1  I have no idea why some people give bad review...      5\n",
       "2  love the gyro plate. Rice is so good and I als...      4\n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5\n",
       "4  General Manager Scott Petello is a good egg!!!...      5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yelp Reviews\n",
    "import pandas as pd\n",
    "url=('https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Practice/master/Data/yelp.csv')\n",
    "yelp= pd.read_csv(url)[['text','stars']]\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0f3c3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>Yes I do rock the hipster joints.  I dig this ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>Only 4 stars? \\n\\n(A few notes: The folks that...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>I'm not normally one to jump at reviewing a ch...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>Let's see...what is there NOT to like about Su...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4086 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  stars\n",
       "0     My wife took me here on my birthday for breakf...      5\n",
       "1     I have no idea why some people give bad review...      5\n",
       "2     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5\n",
       "3     General Manager Scott Petello is a good egg!!!...      5\n",
       "4     Drop what you're doing and drive here. After I...      5\n",
       "...                                                 ...    ...\n",
       "4081  Yes I do rock the hipster joints.  I dig this ...      5\n",
       "4082  Only 4 stars? \\n\\n(A few notes: The folks that...      5\n",
       "4083  I'm not normally one to jump at reviewing a ch...      5\n",
       "4084  Let's see...what is there NOT to like about Su...      5\n",
       "4085  4-5 locations.. all 4.5 star average.. I think...      5\n",
       "\n",
       "[4086 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp=yelp[yelp.stars.isin([1,5])].reset_index(drop=True)\n",
    "yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83de6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = yelp.loc[0,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b409debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\n",
      "\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
      "\n",
      "Anyway, I can't wait to go back!\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "368b40f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wife take birthday breakfast excellent weather perfect make sit outside overlook ground absolute pleasure waitress excellent food arrive quickly semi-busy saturday morning look like place fill pretty quickly early get good favor get bloody mary phenomenal simply best 've ever 'm pretty sure use ingredient garden blend fresh order amaze everything menu look excellent white truffle scramble egg vegetable skillet tasty delicious come 2 piece griddle bread amaze absolutely make meal complete best `` toast '' 've ever anyway ca n't wait go back\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=word_tokenize(text)\n",
    "words=[word.lower() for word in words]\n",
    "lemmatized_words=[lemmatizer.lemmatize(word, pos = process_pos(pos)) for word,pos in nltk.pos_tag(words) \n",
    "                  if word not in stop_words and word not in punctuation]\n",
    "\n",
    "' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bc3c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    words=word_tokenize(text)\n",
    "    words=[word.lower() for word in words]\n",
    "    lemmatized_words=[lemmatizer.lemmatize(word, pos = process_pos(pos)) for word,pos in nltk.pos_tag(words) \n",
    "                  if word not in stop_words and word not in punctuation]\n",
    "    \n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2544d2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                    text  stars  \\\n",
       "0     My wife took me here on my birthday for breakf...      5   \n",
       "1     I have no idea why some people give bad review...      5   \n",
       "2     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5   \n",
       "3     General Manager Scott Petello is a good egg!!!...      5   \n",
       "4     Drop what you're doing and drive here. After I...      5   \n",
       "...                                                 ...    ...   \n",
       "4081  Yes I do rock the hipster joints.  I dig this ...      5   \n",
       "4082  Only 4 stars? \\n\\n(A few notes: The folks that...      5   \n",
       "4083  I'm not normally one to jump at reviewing a ch...      5   \n",
       "4084  Let's see...what is there NOT to like about Su...      5   \n",
       "4085  4-5 locations.. all 4.5 star average.. I think...      5   \n",
       "\n",
       "                                         processed_text  \n",
       "0     wife take birthday breakfast excellent weather...  \n",
       "1     idea people give bad review place go show plea...  \n",
       "2     rosie dakota love chaparral dog park 's conven...  \n",
       "3     general manager scott petello good egg go deta...  \n",
       "4     drop 're drive eat go back next day food good ...  \n",
       "...                                                 ...  \n",
       "4081  yes rock hipster joint dig place little bit sc...  \n",
       "4082  4 star note folk rat place low must isolate in...  \n",
       "4083  'm normally one jump review chain restaurant e...  \n",
       "4084  let 's see ... like surprise stadium well 9.50...  \n",
       "4085  4-5 location .. 4.5 star average .. think ariz...  \n",
       "\n",
       "[4086 rows x 3 columns]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['processed_text']=yelp.text.apply(process_text)\n",
    "yelp.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "960ba340",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=yelp.processed_text\n",
    "y=yelp.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75954d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "214fc1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64473831",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline(steps=[\n",
    "    ('vect',CountVectorizer (max_features=5000,ngram_range=(1,2))),\n",
    "    ('clf',MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71283e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305283757338552"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)\n",
    "y_test_pred=pipe.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7485b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[163,  22],\n",
       "       [ 49, 788]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "278cdeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443    regular indian place convert buffet lunch comp...\n",
      "17      never deal discount tire phoenix texas service...\n",
      "1257    meet friend dinner restaurant end october like...\n",
      "290     auto repair place 've ever see 5 star solid to...\n",
      "151     call guy evap cooler water pressure line offic...\n",
      "1503    sell car buy carmax spawn original review almo...\n",
      "1021    place great nanny bring dance outfit get strap...\n",
      "1839    've couple time first time first friday expect...\n",
      "2769    dentist great explain medical issue way unders...\n",
      "161     must try mani pedi fan use drive scottsdale se...\n",
      "2295    ok hesitate write review place like 's busy wa...\n",
      "3238    dude claim `` steal souls living '' `` best ph...\n",
      "2040    far favourite department store hand nothing pe...\n",
      "879     place great call 8:30 make appointment afterno...\n",
      "3658    take computer redseven recently friend call te...\n",
      "540     've never location husband take car previously...\n",
      "880     miss place much 's insanity ten high kentucky ...\n",
      "1034    've pass prestige nail walmart 100 time never ...\n",
      "3817    mail call full service ship store owner great-...\n",
      "2757    terrible decision make euthanize 20 year old c...\n",
      "3390    friend go first yasu hear great travel busines...\n",
      "1489    love coach stylish trendy without spend obscen...\n",
      "3204    okay talk coincidence .... day compli-chatting...\n",
      "1564    house clean use pet-friendly product arrive ti...\n",
      "3091    like trendy shit-music half dress plastic surg...\n",
      "3434    weekend debauchery spend 18. somehow break two...\n",
      "1416    's sweetest cut guy work one time total come 5...\n",
      "1393    3 star give day server pat make fun experience...\n",
      "2283    work next door love do excellent job slim fit ...\n",
      "546     love haircut walk wait minute stylist cut exac...\n",
      "1618    update review several week appear maybe manage...\n",
      "788     middle dilemma need proof something fax right ...\n",
      "2777    love place since open change menu little seem ...\n",
      "1827    mexican place like need judge base consistency...\n",
      "1030    great surprise stumble across bank open 7 day ...\n",
      "3497    's emergency generally see asap use live deser...\n",
      "3297    unsuccessfully attempt walk gel posh look `` s...\n",
      "3358    people title company good get eager really goo...\n",
      "2656    young son graduate take buzz boy food city com...\n",
      "3537    5 0 '' require lot alteration essential good a...\n",
      "2029    dude .. manga .... card table ..... heck place...\n",
      "277     video paradise great n't financially comfortab...\n",
      "893     start take car month ago someone business stop...\n",
      "1629    make job ship package lot less miserable purch...\n",
      "996     recently buy house issue speed interference ma...\n",
      "3630    last time vig trick .. see glass door open bac...\n",
      "2694    there gun check upon entry often forget az qui...\n",
      "2015                'm sorry say close door good week ago\n",
      "269     place really make terrible situation easy poss...\n",
      "Name: processed_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_test[(y_test==5)&((y_test_pred==1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337095e5",
   "metadata": {},
   "source": [
    "## How does the model choose between 1-star and 5- star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caf08a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=pipe['vect'].get_feature_names()\n",
    "pipe['clf'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7926e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_star_count=pipe['clf'].feature_count_[0]\n",
    "five_star_count=pipe['clf'].feature_count_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c047899f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1star</th>\n",
       "      <th>5star</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>72.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 min</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 minute</th>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum yum</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yummy</th>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinburger</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucchini</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1star  5star\n",
       "words                  \n",
       "00          24.0   36.0\n",
       "000          2.0    6.0\n",
       "10          72.0  142.0\n",
       "10 min       6.0    1.0\n",
       "10 minute   21.0   11.0\n",
       "...          ...    ...\n",
       "yum yum      0.0    9.0\n",
       "yummy        2.0   96.0\n",
       "zero        16.0    6.0\n",
       "zinburger    0.0   11.0\n",
       "zucchini     1.0    8.0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df=pd.DataFrame({'words':words,'1star':one_star_count,'5star':five_star_count}).set_index('words')\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cf4f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 1 to avoid diving by 0\n",
    "words_df= words_df+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f215197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequencies\n",
    "words_df=words_df/words_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fe77bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1star</th>\n",
       "      <th>5star</th>\n",
       "      <th>1-5</th>\n",
       "      <th>5-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>2.248219</td>\n",
       "      <td>0.444797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>1.426013</td>\n",
       "      <td>0.701256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>1.698584</td>\n",
       "      <td>0.588726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 min</th>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>11.645772</td>\n",
       "      <td>0.085868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 minute</th>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>6.100166</td>\n",
       "      <td>0.163930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1star     5star        1-5       5-1\n",
       "words                                             \n",
       "00         0.000538  0.000239   2.248219  0.444797\n",
       "000        0.000065  0.000045   1.426013  0.701256\n",
       "10         0.001570  0.000924   1.698584  0.588726\n",
       "10 min     0.000151  0.000013  11.645772  0.085868\n",
       "10 minute  0.000473  0.000078   6.100166  0.163930"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute ratios\n",
    "words_df['1-5']=words_df['1star']/words_df['5star']\n",
    "words_df['5-1']=words_df['5star']/words_df['1star']\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "045848db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1star</th>\n",
       "      <th>5star</th>\n",
       "      <th>1-5</th>\n",
       "      <th>5-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>never come</th>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>36.600998</td>\n",
       "      <td>0.027322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor service</th>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>36.600998</td>\n",
       "      <td>0.027322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ugh</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>33.273634</td>\n",
       "      <td>0.030054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste money</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>33.273634</td>\n",
       "      <td>0.030054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad food</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>33.273634</td>\n",
       "      <td>0.030054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1star     5star        1-5       5-1\n",
       "words                                                \n",
       "never come    0.000237  0.000006  36.600998  0.027322\n",
       "poor service  0.000237  0.000006  36.600998  0.027322\n",
       "ugh           0.000215  0.000006  33.273634  0.030054\n",
       "waste money   0.000215  0.000006  33.273634  0.030054\n",
       "bad food      0.000215  0.000006  33.273634  0.030054"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.sort_values(by='1-5',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2756f038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1star</th>\n",
       "      <th>5star</th>\n",
       "      <th>1-5</th>\n",
       "      <th>5-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fantastic</th>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.032462</td>\n",
       "      <td>30.805171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one favorite</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.049662</td>\n",
       "      <td>20.136063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.052815</td>\n",
       "      <td>18.933910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homemade</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.058375</td>\n",
       "      <td>17.130681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.062780</td>\n",
       "      <td>15.928528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1star     5star       1-5        5-1\n",
       "words                                                \n",
       "fantastic     0.000043  0.001325  0.032462  30.805171\n",
       "one favorite  0.000022  0.000433  0.049662  20.136063\n",
       "perfect       0.000086  0.001628  0.052815  18.933910\n",
       "homemade      0.000022  0.000368  0.058375  17.130681\n",
       "yum           0.000022  0.000342  0.062780  15.928528"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.sort_values(by='5-1',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cb891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
